Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                   count    min threads    max threads
------------------  -------  -------------  -------------
all                       1              1              1
generate_mutations        3              1              1
run_interproscan          3              1              1
total                     7              1              1


[Thu Sep 19 17:03:48 2024]
rule generate_mutations:
    input: data/NR4_NR1_ancestors_unaligned.fasta
    output: workflows/NR4_NR1_ancestors_unaligned/fasta/NR4_NR1_ancestors_unaligned_1.fasta
    jobid: 2
    wildcards: dataset_name=NR4_NR1_ancestors_unaligned, rep=1
    resources: tmpdir=/tmp

[Thu Sep 19 17:03:49 2024]
Error in rule generate_mutations:
    jobid: 2
    output: workflows/NR4_NR1_ancestors_unaligned/fasta/NR4_NR1_ancestors_unaligned_1.fasta

RuleException:
CalledProcessError in line 43 of /media/WorkingSpace/Gabe/test_protein_classifier/snakefile:
Command '/opt/miniconda/miniconda3/bin/python /media/WorkingSpace/Gabe/test_protein_classifier/.snakemake/scripts/tmpke9dl9l1.generate_mutations.py' returned non-zero exit status 1.
  File "/media/WorkingSpace/Gabe/test_protein_classifier/snakefile", line 43, in __rule_generate_mutations
  File "/opt/miniconda/miniconda3/lib/python3.7/concurrent/futures/thread.py", line 57, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /media/WorkingSpace/Gabe/test_protein_classifier/.snakemake/log/2024-09-19T170348.607669.snakemake.log
